# -*- coding: utf-8 -*-
"""Heart_Diseases_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eVMDZT7eGZrWZYNL6pw8sOQLzV1LWcBb

Importing dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import  RandomizedSearchCV, train_test_split

"""For Model building """

from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

"""Data collection and processing """

from google.colab import drive
drive.mount('/content/drive')

#loading the csv data to a pandas Datafram
df=pd.read_csv('/content/drive/MyDrive/heart.csv')

df.head()

df.describe()

"""Co-relative data"""

import seaborn as sns
plt.figure(figsize=(20,12))
sns.set_context('notebook',font_scale = 1.3)
sns.heatmap(df.corr(),annot=True,linewidth =2)
plt.tight_layout()

"""Co-relation of the target variables """

sns.set_context('notebook',font_scale = 2.3)
df.drop('target', axis=1).corrwith(df.target).plot(kind='bar', grid=True, figsize=(20, 10), 
                                                        title="Correlation with the target feature")
plt.tight_layout()

"""Age(“age”) Analysis"""

plt.figure(figsize=(25,12))
sns.set_context('notebook',font_scale = 1.5)
sns.barplot(x=df.age.value_counts()[:10].index,y=df.age.value_counts()[:10].values)
plt.tight_layout()

"""Inference:  Here we can see that the 58 age column has the highest frequency.

checking the range of age in the dataset and devising it into 3 parts
"""

minAge=min(df.age)
maxAge=max(df.age)
meanAge=df.age.mean()
print('Min Age :',minAge)
print('Max Age :',maxAge)
print('Mean Age :',meanAge)

Young = df[(df.age>=29)&(df.age<40)]
Middle = df[(df.age>=40)&(df.age<55)]
Elder = df[(df.age>55)]

plt.figure(figsize=(23,10))
sns.set_context('notebook',font_scale = 1.5)
sns.barplot(x=['young ages','middle ages','elderly ages'],y=[len(Young),len(Middle),len(Elder)])
plt.tight_layout()

"""Plotting pie chart """

colors = ['blue','green','yellow']
explode = [0,0,0.1]
plt.figure(figsize=(10,10))
sns.set_context('notebook',font_scale = 1.2)
plt.pie([len(Young),len(Middle),len(Elder)],labels=['young ages','middle ages','elderly ages'],explode=explode,colors=colors, autopct='%1.1f%%')
plt.tight_layout()

"""Sex(“sex”) Feature Analysis"""

plt.figure(figsize=(18,9))
sns.set_context('notebook',font_scale = 1.5)
sns.countplot(df['sex'])
plt.tight_layout()

"""Chest Pain Type(“cp”) Analysis"""

plt.figure(figsize=(18,9))
sns.set_context('notebook',font_scale = 1.5)
sns.countplot(df['cp'])
plt.tight_layout()

"""Inference: As seen, there are 4 types of chest pain

status at least
condition slightly distressed
condition medium problem
condition too bad

Inference: As seen, there are 4 types of chest pain

status at least
condition slightly distressed
condition medium problem
condition too bad

**Analyzing cp vs target column**

Inference: From the above graph we can make some inferences,

People having the least chest pain are not likely to have heart disease.
People having severe chest pain are likely to have heart disease

Thal Analysis
"""

plt.figure(figsize=(18,9))
sns.set_context('notebook',font_scale = 1.5)
sns.countplot(df['thal'])
plt.tight_layout()

plt.figure(figsize=(18,9))
sns.set_context('notebook',font_scale = 1.5)
sns.countplot(df['target'])
plt.tight_layout()

categorical_val = []
continous_val = []
for column in df.columns:
    print("--------------------")
    print(f"{column} : {df[column].unique()}")
    if len(df[column].unique()) <= 10:
        categorical_val.append(column)
    else:
        continous_val.append(column)

categorical_val.remove('target')
dfs = pd.get_dummies(df, columns = categorical_val)
dfs.head(6)

"""Modelling

Splitting our Dataset
"""

X = dfs.drop('target', axis=1)
y = dfs.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""The KNN MAchine LEarning algorithm """

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 10)
knn.fit(X_train,y_train)
y_pred1 = knn.predict(X_test)
print(accuracy_score(y_test,y_pred1))

"""Conclusion on Heart Disease Prediction

 We did data visualization and data analysis of the target variable, age features, and whatnot along with its univariate analysis and bivariate analysis.

  From the above model accuracy, KNN is giving us the accuracy which is 71%
"""